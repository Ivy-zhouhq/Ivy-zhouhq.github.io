<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Review on GAN |  
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-paper_200830_GAN"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Review on GAN
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/08/30/paper_200830_GAN/" class="article-date">
  <time datetime="2020-08-30T18:50:55.000Z" itemprop="datePublished">2020-08-30</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>The most comprehensive review of GAN in history 2020 edition: algorithms, theories and applications.<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2001.06937.pdf">A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications</a></p>
<p><em>Since I had a project on GAN, I explored deeply about various GAN.</em></p>
<p>In recent years, Generative Adversarial Networks (GAN) has been a hot research topic. Since 2014, researchers have conducted extensive research on GAN and proposed a large number of algorithms. However, there are few comprehensive studies to explain the connections between different GAN variants and the way they evolved. In this article, we try to review a variety of GAN methods from the perspectives of algorithms, theory, and applications. First, we introduced in detail the research motivation, mathematical representation and architecture of most GAN algorithms. In addition, GAN has been combined with other machine learning algorithms in some specific applications, such as semi-supervised learning, transfer learning and reinforcement learning. This article compares the similarities and differences of these GAN methods. Secondly, we studied the theoretical issues related to GAN. Third, we explained the typical applications of GAN in image processing and computer vision, natural language processing, music, speech and audio, medicine, and data science. Finally, we pointed out some future open research issues for GAN.</p>
<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h1><p>In this section, we first introduce the most primitive GAN. Then, introduce its representative variants, training and evaluation methods, and task-driven GAN.</p>
<h2 id="Generative-confrontation-network"><a href="#Generative-confrontation-network" class="headerlink" title="Generative confrontation network"></a>Generative confrontation network</h2><p>When the models are all neural networks, the GAN architecture is very intuitive to implement. In order to learn the distribution p_g of the generator on the data x, first define a prior distribution p_z(z)[3] about the input noise variable, where z is the noise variable. Next, GAN represents the mapping from noise space to data space G(z, θ_g), where G is a differentiable function represented by a neural network with a parameter θ_g. In addition to G, another neural network D(x, θ_d) is also defined by the parameter θ_d, and the output of D(x) is a scalar. D(x) represents the probability that x comes from the real data instead of from the generator G. We train the discriminator D to maximize the probability of providing the correct label for the training data and the fake samples generated by the generator G. At the same time, we train G to minimize log(1-D(G(z))).</p>
<h3 id="Objective-function"><a href="#Objective-function" class="headerlink" title="Objective function"></a>Objective function</h3><p>GAN can use a variety of different objective functions.</p>
<h4 id="The-most-primitive-minimax-game"><a href="#The-most-primitive-minimax-game" class="headerlink" title="The most primitive minimax game"></a>The most primitive minimax game</h4><p>The objective function of GAN [3] is<br>$$<br>\begin{array}{l}<br>\min <em>{G} \max <em>{D} V(D, G)=E</em>{x \sim p</em>{\text {data}}(x)}[\log D(x)] \<br>\quad+E_{z \sim p_{z}(z)}[\log (1-D(G(z)))]<br>\end{array}<br>$$<br>Where D(x) is the cross entropy between $[1, 0]^{T}$ and $[D(x), 1-D(x)]^T$. Similarly, log(1-D(G(z))) is the cross entropy between $[0, 1]^T$ and $[D(G(z)), 1-D(G(z))]^T$. For a fixed G, the optimal discriminator D is given in [3]:<br>$$<br>D_{G}^{<em>}(x)=\frac{p_{\text {data}}(x)}{p_{\text {data}}(x)+p_{g}(x)}<br>$$<br>The mini-max game in the formula can be reformulated as:<br>$$<br>\begin{array}{l}<br>C(G)=\max <em>{D} V(D, G) \<br>=E</em>{x \sim p_{\text {data}}}\left[\log D_{G}^{</em>}(x)\right] \<br>\quad+E_{z \sim p_{z}}\left[\log \left(1-D_{G}^{<em>}(G(z))\right)\right] \<br>=E_{x \sim p_{\text {data}}}\left[\log D_{G}^{</em>}(x)\right]+E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{*}(x)\right)\right] \<br>=E_{x \sim p_{\text {data}}}\left[\log \frac{p_{\text {data}}(x)}{\frac{1}{2}\left(p_{\text {data}}(x)+p_{g}(x)\right)}\right] \<br>\quad+E_{x \sim p_{g}}\left[\frac{p_{g}(x)}{\frac{1}{2}\left(p_{\text {data}}(x)+p_{g}(x)\right)}\right]-2 \log 2<br>\end{array}<br>$$<br>The KL divergence and JS divergence between two probability distributions p(x) and q(x) are defined as follows:<br>$$<br>K L(p | q)=\int p(x) \log \frac{p(x)}{q(x)} d x<br>$$<br>$$<br>J S(p | q)=\frac{1}{2} K L\left(p | \frac{p+q}{2}\right)+\frac{1}{2} K L\left(q | \frac{p+q}{2}\right)<br>$$<br>$$<br>\begin{array}{l}<br>C(G)=K L\left(p_{\text {data}} | \frac{p_{\text {data}}+p_{g}}{2}\right)+K L\left(p_{g} | \frac{p_{\text {data}}+p_{g}}{2}\right)-2 \log 2 \<br>=2 J S\left(p_{\text {data}} | p_{g}\right)-2 \log 2<br>\end{array}<br>$$<br>Therefore, the objective function of GAN and KL divergence are related to JS divergence.</p>
<h4 id="Unsaturated-game"><a href="#Unsaturated-game" class="headerlink" title="Unsaturated game"></a>Unsaturated game</h4><p>In fact, formula may not provide a large enough gradient for G to learn well. Generally speaking, G has poor performance in the early stages of the learning process, and the generated samples are significantly different from the training data. Therefore, D can reject the samples generated by G with high confidence. In this case, log(1-D(G(z))) is saturated. We can train G to maximize log(D(G(z))) instead of minimizing log(1-D(G(z))). The loss of the generator becomes<br>$$<br>\begin{array}{l}<br>J^{(G)}=E_{z \sim p_{z}(z)}[-\log (D(G(z)))] \<br>=E_{x \sim p_{g}}[-\log (D(x))]<br>\end{array}<br>$$<br>This new objective function can make D and G reach the same fixed point during the training process, but provides a much larger gradient in the early stage of learning. Unsaturated games are heuristic, not theory-driven. However, there are other problems in the unsaturated game, such as the unstable numerical gradient used to train G. Under the optimal D<em><em>G, there are<br>$$<br>\begin{array}{l}<br>E</em>{x \sim p_{g}}\left[-\log \left(D_{G}^{</em>}(x)\right)\right]+E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{<em>}(x)\right)\right] \<br>=E_{x \sim p_{g}}\left[\log \frac{\left(1-D_{G}^{</em>}(x)\right)}{D_{G}^{<em>}(x)}\right]=E_{x \sim p_{g}}\left[\log \frac{p_{g}(x)}{p_{\text {data}}(x)}\right] \<br>=K L\left(p_{g} | p_{\text {data}}\right)<br>\end{array}<br>$$<br>Therefore E_(x~p_g)[-log(D</em><em>G(x))] is equivalent to<br>$$<br>\begin{array}{l}<br>E</em>{x \sim p_{g}}\left[-\log \left(D_{G}^{<em>}(x)\right)\right] \<br>=K L\left(p_{g} | p_{\text {data}}\right)-E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{</em>}(x)\right)\right]<br>\end{array}<br>$$<br>$$<br>\begin{array}{l}<br>E_{x \sim p_{\text {data}}}\left[\log D_{G}^{<em>}(x)\right]+E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{</em>}(x)\right)\right] \<br>=2 J S\left(p_{\text {data}} | p_{g}\right)-2 \log 2<br>\end{array}<br>$$<br>Therefore E_(x~p_g)[log^(1-D<em><em>G(x))] is equivalent to<br>$$<br>\begin{array}{l}<br>E</em>{x \sim p_{g}}\left[\log \left(1-D_{G}^{</em>}(x)\right)\right] \<br>=2 J S\left(p_{\text {data}} | p_{g}\right)-2 \log 2-E_{x \sim p_{\text {data}}}\left[\log D_{G}^{<em>}(x)\right]<br>\end{array}<br>$$<br>Finally we get<br>$$<br>\begin{array}{l}<br>E_{x \sim p_{g}}\left[-\log \left(D_{G}^{</em>}(x)\right)\right] \<br>=K L\left(p_{g} | p_{\text {data}}\right)-2 J S\left(p_{\text {data}} | p_{g}\right)+ \<br>E_{x \sim p_{\text {data}}}\left[\log D_{G}^{*}(x)\right]+2 \log 2<br>\end{array}<br>$$<br>It can be seen from the above formula that the optimization of the alternative G loss function in the unsaturated game is contradictory, because the first goal is to make the difference between the generated distribution and the actual distribution as small as possible, and because of the existence of the negative sign The second goal is to make the difference between these two distributions as large as possible. This will bring unstable numerical gradients for training G. In addition, KL divergence is an asymmetric measure, which can be reflected in the following two examples<br>$$<br>\begin{aligned}<br>&amp;\text { If } p_{\text {data}}(x) \rightarrow 0 \text { and } p_{g}(x) \rightarrow 1, \text { we have }\<br>&amp;K L\left(p_{g} | p_{d a t a}\right) \rightarrow+\infty\<br>&amp;\text { If } p_{\text {data}}(x) \rightarrow 1 \text { and } p_{g}(x) \rightarrow 0, \text { we have }\<br>&amp;K L\left(p_{g} | p_{d a t a}\right) \rightarrow 0<br>\end{aligned}<br>$$<br>The penalties for the two errors of G are completely different. The first error is that G produces unreal samples, and the corresponding penalty is large. The second type of error is that G fails to produce real samples, and the penalty is small. The first type of error is that the generated samples are inaccurate, and the second type of error is that the generated samples are not diverse enough. Based on this principle, G tends to generate repeated but safe samples, rather than risk generating different but unsafe samples, which will lead to the problem of mode collapse.</p>
<h4 id="Maximum-likelihood-game"><a href="#Maximum-likelihood-game" class="headerlink" title="Maximum likelihood game"></a>Maximum likelihood game</h4><p>In GAN, there are many ways to approximate first equation. Assuming that the discriminator is optimal, we want to minimize<br>$$<br>\begin{array}{l}<br>J^{(G)}=E_{z \sim p_{z}(z)}\left[-\exp \left(\sigma^{-1}(D(G(z)))\right)\right] \<br>=E_{z \sim p_{z}(z)}[-D(G(z)) /(1-D(G(z)))]<br>\end{array}<br>$$<br>There are other possible methods to approach the maximum likelihood in the GAN framework [17]. Figure 1 shows the comparison between the original zero-sum game, the unsaturated game, and the maximum likelihood game.<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjw1nv4taaj30g00k2762.jpg"><br>From Figure 1, three observations can be obtained.</p>
<p>First, when the sample may come from the generator, that is, at the left end of the graph, both the maximum likelihood game and the original minimax game are affected by gradient dispersion, while heuristic unsaturated games do not have this problem.</p>
<p>Second, there is a problem with the maximum likelihood game, that is, almost all gradients come from the right end of the curve, which means that only a small part of the samples in each minibatch dominate the calculation of the gradient. This shows that the method of reducing sample variance may be an important research direction to improve the performance of GAN based on maximum likelihood game.</p>
<p>Third, the sample variance of the heuristic-based unsaturated game is low, which may be the possible reason for its more successful application in practical applications.</p>
<p>M.Kahng et al. [124] proposed GAN Lab, which provides an interactive visualization tool for non-professionals to learn GAN and do experiments. Bau et al. [125] proposed an analysis framework to visualize and understand GAN.</p>
<h2 id="Representative-GAN-variants"><a href="#Representative-GAN-variants" class="headerlink" title="Representative GAN variants"></a>Representative GAN variants</h2><p>There are many papers related to GAN [126]-[131], such as CSGAN [132] and LOGAN [133]. In this section, we will introduce some representative GAN variants.</p>
<ol>
<li>InfoGAN</li>
<li>ConditionalGANs(cGANs)</li>
<li>CycleGAN</li>
<li>f-GAN</li>
<li>IntegralProbabilityMetrics(IPMs) </li>
<li>LossSensitiveGAN(LS-GAN)</li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjw1p5v1ezj30g0048jre.jpg"></p>
<h2 id="GAN-training"><a href="#GAN-training" class="headerlink" title="GAN training"></a>GAN training</h2><p>Although there are unique solutions in theory, for many reasons [29], [32], [179], GAN training is difficult and often unstable. One of the difficulties comes from the fact that the optimal weight of GAN corresponds to the saddle point of the loss function, not the minimum point.</p>
<p>There are many papers on GAN training. Yadav et al. [180] used prediction methods to make GAN training more stable. [181] By using independent learning rates, two time scale update rules (TTUR) are proposed for the discriminator and generator to ensure that the model can converge to a stable local Nash equilibrium. Arjovsky [179] conducted a theoretical study to fully understand the training dynamics of GAN, analyzed why GAN is difficult to train, studied and strictly proved the saturation and instability of the loss function when training GAN, and proposed a solution A practical and theoretical direction for this kind of problems, and new tools are introduced to study them. Liang et al. [182] believe that the training of GAN is a continuous learning problem [183].</p>
<p>One way to improve GAN training is to evaluate the empirical “symptoms” that may occur during training. These symptoms include: the generator collapses to the extent that it can only generate extremely similar samples for different inputs [29]; the discriminator loss quickly converges to zero [179], and it cannot provide gradient updates for the generator; making the generator and discriminator be the same It is difficult for the model to converge [32].</p>
<h2 id="GAN-evaluation-index"><a href="#GAN-evaluation-index" class="headerlink" title="GAN evaluation index"></a>GAN evaluation index</h2><p>In this section, we explain some evaluation indicators used in GAN [215], [216]:</p>
<ol>
<li>InceptionScore(IS)</li>
<li>Modescore(MS)</li>
<li>FrechetInceptionDistance(FID)</li>
<li>Multi-scalestructuralsimilarity(MS-SSIM)</li>
</ol>
<p>How to choose a good evaluation index for GAN is still a difficult problem [225]. Xu et al. [219] proposed an empirical study on GAN evaluation indicators. Karol Kurach [224] conducted a large-scale research on regularization and normalization in GAN. There are other comparative studies on GAN, such as [226]. References [227] proposes several metrics as meta-metrics to guide researchers in choosing quantitative evaluation indicators. Appropriate evaluation indicators should distinguish real samples from generated fake samples, verify mode drop or mode collapse, and detect overfitting. Hope there will be a better way to evaluate the quality of GAN models in the future.</p>
<h2 id="Task-driven-GAN"><a href="#Task-driven-GAN" class="headerlink" title="Task-driven GAN"></a>Task-driven GAN</h2><p>This article focuses on the GAN model. At present, there is a large amount of literature on closely related fields involving specific tasks.</p>
<ol>
<li>Semi-supervised learning</li>
<li>Transfer learning</li>
<li>Reinforcement learning</li>
<li>Multimodal learning</li>
</ol>
<p>GAN has been used in the field of feature learning, such as feature selection [277], hashing [278]-[285] and metric learning [286]. MisGAN [287] can learn from incomplete data through GAN. Evolutionary GAN (Evolutionary GAN) was proposed in [288]. Ponce et al. [289] combined GAN and genetic algorithm to evolve images for visual neurons. GAN is also used in other machine learning tasks [290], such as active learning [291], [292], online learning [293], ensemble learning [294], zero-sample learning [295], [296] and multi-task learning [297].</p>
<h1 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h1><h2 id="Maximum-likelihood-estimation-MLE"><a href="#Maximum-likelihood-estimation-MLE" class="headerlink" title="Maximum likelihood estimation (MLE)"></a>Maximum likelihood estimation (MLE)</h2><p>Not all generative models use MLE. Some generative models do not use MLE, but can be modified to use MLE (GANs fall into this category). It can be simply proved that minimizing the KL divergence (KLD) between p_data(x) and p_g(x) is equivalent to maximizing the log likelihood when the number of samples m increases:<br>$$<br>\begin{array}{l}<br>\theta^{*}=\underset{\theta}{\arg \min } K L D\left(p_{\text {data}} | p_{g}\right) \<br>=\underset{\theta}{\arg \min }-\int p_{\text {data}}(x) \log \frac{p_{g}(x)}{p_{\text {data}}(x)} d x \<br>=\arg \min \int p_{\text {data}}(x) \log p_{\text {data}}(x) d x \<br>\quad-\int p_{\text {data}}(x) \log p_{g}(x) d x \<br>=\arg \max <em>{\theta} \log p</em>{\text {data}}(x) \log <em>{g}(x) d x \<br>=\arg \max _{\theta} \lim _{m \rightarrow \infty} \frac{1}{m} \sum</em>{i=1}^{m} \log p_{g}\left(x_{i}\right)<br>\end{array}<br>$$</p>
<p>In order to ensure symbol consistency, the model probability distribution p_θ(x) is replaced with p_g(x). For more information on MLE and other statistical estimators, see Chapter 5 of [298].</p>
<h2 id="Model-collapse"><a href="#Model-collapse" class="headerlink" title="Model collapse"></a>Model collapse</h2><p>GANs are difficult to train, and in [26], [29] it has been observed that they are often affected by mode collapse [299], [300], where the generator learns to generate samples based on only a few data distribution patterns, and ignores Many other patterns (even if there are samples from missing patterns in the entire training data). In the worst case, the generator only generates a single sample (completely collapsed) [179], [301].</p>
<p>In this section, we first introduce two views on the collapse of the GAN model: the divergence view and the algorithm view. Then, we will introduce methods for solving model collapse by proposing new objective functions or new architectures, including objective function-based methods and architecture-based methods.</p>
<h2 id="Other-theoretical-issues"><a href="#Other-theoretical-issues" class="headerlink" title="Other theoretical issues"></a>Other theoretical issues</h2><p>Other theoretical issues include:</p>
<ol>
<li>Has GAN really learned the distribution?</li>
<li>Divergence/distance</li>
<li>Inverse mapping</li>
<li>Mathematical point of view (such as optimization)</li>
<li>Memory</li>
</ol>
<h1 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h1><p>As mentioned earlier, GAN is a powerful generative model that can generate realistic samples from a random vector z. We neither need to know the explicit true data distribution or make any other mathematical assumptions. These advantages make GAN can be widely used in many fields, such as image processing and computer vision, sequence data and so on.</p>
<h2 id="Image-processing-and-computer-vision"><a href="#Image-processing-and-computer-vision" class="headerlink" title="Image processing and computer vision"></a>Image processing and computer vision</h2><p>The most successful applications of GAN are in image processing and computer vision, such as image super-resolution, image generation and manipulation, and video processing.</p>
<p>Super resolution<br>Image composition and manipulation<br>Texture synthesis<br>Target Detection<br>Video application</p>
<h2 id="Sequence-data"><a href="#Sequence-data" class="headerlink" title="Sequence data"></a>Sequence data</h2><p>GAN has also made certain achievements in sequence data such as natural language, music, speech, audio [376], [377], time sequence [378]–[381], etc.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        share
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2020/08/30/paper_200830_GAN/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2020/09/01/shallow_GCN/" class="article-nav-link">
        <strong class="article-nav-caption">last article</strong>
        <div class="article-nav-title">
          
            First Encounter with GCN
          
        </div>
      </a>
    
    
      <a href="/2020/08/27/shallow_bot3/" class="article-nav-link">
        <strong class="article-nav-caption">next article</strong>
        <div class="article-nav-title">Think about Bot 3</div>
      </a>
    
  </nav>

  
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2017-2020
        <i class="ri-heart-fill heart_icon"></i> Hanqi ZHOU
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Hanqi ZHOU"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">Home</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">Blog</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/life">Life</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">About Me</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>