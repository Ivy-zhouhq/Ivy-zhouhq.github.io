<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
     
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

  
  

  

</head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">Hanqi ZHOU</a></h1>
      <div id="subtitle-box">
        
          <span id="subtitle">never ever compromise</span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>




<!-- Subtitle -->

<div id="main">
  <section class="outer">
  
  
<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content">The explanation of Bayes&#39; theorem is awesome. The important thing is the Bayesian way of thinking, not memorizing the formula.</div>
</div>


<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-paper_201018_BNM"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/10/18/paper_201018_BNM/"
    >Batch Nuclear-norm Maximization</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/10/18/paper_201018_BNM/" class="article-date">
  <time datetime="2020-10-18T18:50:55.000Z" itemprop="datePublished">2020-10-18</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>Batch Nuclear-norm Maximization，BNM<br>In transfer learning tasks, there have always been such problems:<br>Since the target domain has no label, it often leads to more confusing data near the interface.<br>Cui Shuhao, a graduate student of the Institute of Computing Technology of the Chinese Academy of Sciences, proposed a new solution: Batch Nuclear-norm Maximization (BNM).</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1y8v1fobj312o0aagpk.jpg"></p>
<p>In typical under-label scenarios (such as semi-supervised learning, etc.), BNM can effectively improve the learning effect.<br>Moreover, a large number of experiments show that the performance of BNM is better than some of the current mainstream methods, and when used in combination, the effect is also very good.<br>This paper has been accepted as CVPR 2020 Oral.</p>
<h2 id="Core"><a href="#Core" class="headerlink" title="Core"></a>Core</h2><p>Main idea:<br>The discrimination and diversity of category prediction also point to the kernel norm of the batch response matrix, so that the batch kernel norm can be maximized to improve the performance of the target domain in the migration problem.<br>You can try to optimize the discrimination and mobility by analyzing the batch matrix A composed of batch category responses.</p>
<h3 id="Discriminative"><a href="#Discriminative" class="headerlink" title="Discriminative"></a>Discriminative</h3><p>The so-called discriminativeness refers to whether the process of predicting the category is firm. For example, the response to the second type of question:</p>
<ol>
<li>[0.9,0.1] is highly discriminative</li>
<li>[0.6,0.4] is less discriminative.<br>Common methods use minimizing entropy to obtain higher discriminativeness. We find that the F-norm of matrix A and entropy have the opposite monotonicity, so that the discriminativeness can be improved by maximizing the F-norm of A.<h3 id="Diversity"><a href="#Diversity" class="headerlink" title="Diversity"></a>Diversity</h3>Diversity can be approximately expressed as the number of categories predicted in the batch matrix, that is, the greater the number of predicted categories, the greater the response diversity.<br>Consider the linear correlation of the responses of different categories. If two responses belong to different categories, the responses will be quite different. Linearly irrelevant, if they belong to the same category, they will be approximately linearly related:</li>
<li>[0.9,0.1] has nothing to do with [0.1,0.9] linearly</li>
<li>[0.9,0.1] is approximately linearly related to [0.8,0.2].<br>Then the number of predicted categories is the largest number of linearly independent vectors in the matrix, that is, the rank of the matrix.</li>
</ol>
<h3 id="BNM"><a href="#BNM" class="headerlink" title="BNM"></a>BNM</h3><p>The kernel norm is the sum of the singular values ​​of the matrix. There are two conclusions in mathematics:</p>
<ol>
<li>The limit between nuclear norm and F norm</li>
<li>The kernel norm is the convex approximation of the matrix rank<br>Therefore, the discriminability and diversity of category prediction also point to the kernel norm of the matrix, and we can maximize the matrix kernel norm (BNM) to improve the performance of prediction.</li>
</ol>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>In the commonly used frameworks Pytorch and Tensorflow, BNM can be implemented with one line of code.<br>Pytorch:</p>
<pre><code>L_BNM = -torch.norm(A, &#39;nuc&#39;) </code></pre>
<p>TensorFlow：</p>
<pre><code>L_BNM = -tf. reduce_sum(tf.svd(A, compute_uv=False))</code></pre>
<h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>We apply BNM to three under-labeled scenarios: semi-supervised learning, domain adaptation, and open domain object recognition.<br>Experiments show that the existing methods can be improved in semi-supervised learning; BNM constraints are significantly better than EntMin in domain adaptation, and a single BNM constraint can achieve performance similar to existing methods, as shown in the following figure:</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1yc54571j30u00c640l.jpg"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/2020/" rel="tag">2020</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/transfer/" rel="tag">transfer</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-paper_201011"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/10/11/paper_201011/"
    >A Meta-learning Causal Structure</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/10/11/paper_201011/" class="article-date">
  <time datetime="2020-10-11T18:50:55.000Z" itemprop="datePublished">2020-10-11</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>Propose a meta-learning causal structure based on the speed of the learner adapting to the new distribution</p>
<p>Yoshua Bengio et al. proposed a meta-learning causal structure based on the speed at which the learner adapts to new distributions caused by interventions, agent actions, and other non-stationarity-induced sparse distribution changes. This research proves that under this assumption, the correct choice of causal structure will make the learner adapt to the modified distribution more quickly, because after the learned knowledge is properly modularized, the distribution changes will be concentrated in one or more mechanisms . This leads to sparse expected gradients and a small number of effective degrees of freedom that need to be relearned when adapting to such changes. Therefore, this study takes the speed of adapting to the modified distribution as the goal of meta-learning, showing that this can be used to determine the causal relationship between two observed variables.</p>
<p>The distribution change does not require corresponding standard intervention, and the learner does not have direct knowledge about the intervention. The study proved that the causal structure can be parameterized by continuous variables and learned in an end-to-end format. The researchers also explored how to use these ideas to learn encoders to map low-level observed variables and unobserved causal variables that lead to faster out-of-distribution adaptations, and then learn a representation space that satisfies independent mechanisms and actions and instability The resulting hypothesis of small sparse changes within the mechanism.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1yfa63bij30u00a7dgf.jpg"></p>
<h1 id="The-generalization-problem-of-machine-learning-methods"><a href="#The-generalization-problem-of-machine-learning-methods" class="headerlink" title="The generalization problem of machine learning methods"></a>The generalization problem of machine learning methods</h1><p>Current machine learning methods have weak generalization effects on data outside the training distribution, and generalization is inevitable in practice. Therefore, it is not enough to achieve excellent generalization results on the test set from the same distribution as the training data. We also hope that the content learned on one data set can achieve good generalization on other related distributions. These distributions may contain concepts that the learner has seen, and the changes usually result from the actions of the agent. Generally speaking, we hope that the previously learned knowledge can form a solid foundation, so that the learner can quickly adapt to the new correlation distribution, that is, to obtain excellent transfer results. The learner may still need to learn some new concepts, but since most other related concepts (and their composition) have been captured by the learner, the learning on the transfer distribution will be very rapid.</p>
<p>In the absence of assumptions, it is impossible to achieve successful migration on unrelated distributions. This research assumes that when knowledge is represented in an appropriate modular way, the distribution changes are sparse, and only one or a few modules change. This is especially true when the distribution change is caused by the actions of one or more agents (such as interventions discussed in the causality literature), that is, the causal variable is limited to a certain value. Generally, it is difficult for an agent to affect multiple underlying causal variables at the same time. Although the study does not involve much agent learning, it uses the agent learning environment to help discover these variables and their causal relationships.</p>
<p>To stimulate the need for causal structure inference, you need to consider implementing interventions in real or imagined. To plan appropriately in a way that considers intervention, you need to imagine the change in the joint distribution of variables caused by the intervention, even if you have never seen such a change before. This is beyond the scope of good transfer learning and requires causal learning and causal reasoning. Therefore, just learning the joint distribution of the observed variables is not enough. You should also fully study the underlying high-level variables and their causal relationships with appropriate inferences about intervention effects. For example, A=Raining causes B=Open Umbrella (not vice versa). Changing the marginal probability of Raining (for example, due to changes in weather) will not change the correlation mechanism between A and B (P(B|A)), but it will affect P(B). Conversely, the agent’s intervention on B (Open umbrella) will not affect A (Raining). This asymmetry is usually not seen in the training pair (A, B) unless the distribution changes, such as a change in the distribution caused by intervention.</p>
<p>This is the motivation of the research, that is, the learner learns based on a set of distributions brought about by the intervention that is not necessarily known, not only can capture the joint distribution, but also discover some underlying causal structures.</p>
<h1 id="New-ideas-from-Yoshua-Bengio-and-others"><a href="#New-ideas-from-Yoshua-Bengio-and-others" class="headerlink" title="New ideas from Yoshua Bengio and others"></a>New ideas from Yoshua Bengio and others</h1><p>Machine learning methods usually make use of some form of data distribution assumption (there is no free lunch theorem that tells us not to have confidence in generalization). This research not only considers the hypothesis of data distribution, but also considers the change of the distribution (for example, due to some actions of the agent, the training distribution changes to the migration distribution). The research relies on the assumption that when knowledge about the distribution is properly represented, the change in the distribution is small. This is due to the underlying assumption (but it is difficult to directly verify this assumption): due to a generalized form of intervention that causes the distribution to change, only one or a few truth-value mechanisms have changed.</p>
<p>How can this assumption be used? The research carried out theoretical and experimental verification and found that if you have the correct knowledge representation, a well-trained model on the training distribution can quickly adapt to the migration distribution. This is due to the hypothesis of the study: the truth-value data generation process is an integral part of the independent mechanism. When the training distribution becomes the migration distribution, only a few truth-value mechanisms and parameters need to be changed. Therefore, the model that captures the corresponding knowledge decomposition requires only a few updates and examples to adapt to the migration distribution. The following will show that the expected gradient on the unchanged parameters is close to 0 (provided that the model is well trained on the training distribution), so the effective search space will be greatly reduced in the process of adapting to the migration distribution, thereby achieving rapid adaptation .</p>
<p>Therefore, based on the hypothesis that “the correct knowledge representation space brings about small distribution changes”, the researchers defined a meta-learning goal that measures the speed of adaptation, thereby optimizing the way of representing, decomposing and structuring knowledge. This is the core idea of ​​the research. Note that the signal obtained when there is more instability (that is, a lot of changes in the distribution) will be stronger, just as more meta-examples in meta-learning will lead to better results.</p>
<p>In this way, the researcher converts what is usually considered troublesome in the field of machine learning (unsteady state, uncontrolled intervention, etc.) into a training signal, thereby finding an appropriate way to decompose knowledge into matching small Change the components and mechanisms of this hypothesis. Therefore, researchers finally optimize the rapid migration and robustness of distribution changes in an end-to-end manner. If the data is really generated based on the components of an independent causal mechanism, there is a knowledge decomposition that mimics the structure. If in each time step, the real-world agent can only change one or a small number of high-level variables (or the related mechanisms that generate these high-level variables), then the research’s hypothesis about small changes (represented by correct knowledge) is verified. In addition, in addition to achieving rapid migration, the study may be able to restore the approximation of true causality to independent mechanisms (to the extent that observations and interventions can reveal these mechanisms).</p>
<h1 id="cause-and-effect-diagram"><a href="#cause-and-effect-diagram" class="headerlink" title="cause and effect diagram"></a>cause and effect diagram</h1><p>Learn the cause and effect diagram with two discrete variables</p>
<p>Assuming that A and B are discrete variables that can take N possible values, consider using the following formulas (A → B model and B → A model) to estimate their joint distribution:<br>$$<br>\begin{array}{l}<br>P_{A \rightarrow B}(A, B)=P_{A \rightarrow B}(A) P_{A \rightarrow B}(B \mid A) \<br>P_{B \rightarrow A}(A, B)=P_{B \rightarrow A}(B) P_{B \rightarrow A}(A \mid B)<br>\end{array}<br>$$</p>
<p><strong>Experiments on adaptation to transfer distribution</strong></p>
<p>The researchers conducted multiple experiments to compare the learning curve of the correct causal model and the incorrect model on the migration distribution. The adaptation of only a small number of gradient steps on the data from different but relevant migration distributions is essential to obtain the signal usable by the meta-learning algorithm. In order to demonstrate the effect of adaptation and promote the use of a small amount of data from the migration distribution, the researchers experimented with the model on discrete random variables, which can take N = 10 possible values.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1yh1mbaij30u00ggwfx.jpg"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/meta/" rel="tag">meta</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-paper_201004"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/10/04/paper_201004/"
    >Evolving Normalization-Activation Layers</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/10/04/paper_201004/" class="article-date">
  <time datetime="2020-10-04T18:50:55.000Z" itemprop="datePublished">2020-10-04</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.02967">Evolving Normalization-Activation Layers</a></p>
<p>Batch normalization and activation functions are important components of deep neural networks, and their positions often coincide. In the past neural network design, the two were usually designed separately. Recently, Google Brain and DeepMind researchers have jointly proposed a new scheme: <strong>unify the two into a computational graph, and start structural evolution from low-level primitives. Researchers use layer search algorithm to find a new set of normalization-activation layer EvoNorms.</strong> Some of these layers are independent of batch statistics.</p>
<p>Experiments have proved that EvoNorms is not only effective on multiple image classification models including ResNets, MobileNets and EfficientNets, but it can also be well migrated to Mask R-CNN model (for instance segmentation) and BigGAN (for image synthesis) . In many cases, the performance of EvoNorms is significantly better than the layers based on BatchNorm and GroupNorm.</p>
<h2 id="Search-space"><a href="#Search-space" class="headerlink" title="Search space"></a>Search space</h2><p>The researchers represented each normalization-activation layer as a computational graph, that is, converting the input tensor to the output tensor of the same shape (see Figure 1). Each intermediate node represents a unary or binary operation (see Table 1). These operations are designed to preserve the dimensions of the input tensor to ensure that the shapes of the nodes in the calculation graph are compatible with each other. The calculation graph has 4 initial nodes: input tensor, constant zero tensor, and two trainable vectors v_0 and v_1 along the channel dimension initialized to 0 and 1.<br><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1ynrgcm7j30qu0c40tr.jpg"><br><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1yni6sx3j30pg0ykq5c.jpg"></p>
<p>Random graphs can be generated in sequence. Starting from the initial node, the researcher randomly samples primitive operations and randomly samples its input nodes according to the arity of the operation to generate new nodes.</p>
<h2 id="Layer-search-method"><a href="#Layer-search-method" class="headerlink" title="Layer search method"></a>Layer search method</h2><p>The search method used in this study contains the following important parts:</p>
<p>Pair each layer with multiple architectures, and train the model in a lightweight agent task to evaluate the performance of each layer.<br>The evolutionary algorithm is used to optimize the multi-objective boundary, and the efficient rejection mechanism is used to enhance it to filter out unnecessary layers.</p>
<p>Figure 3 below shows the overall workflow of the layer search method:<br><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1ynrgcm7j30qu0c40tr.jpg"></p>
<h3 id="Layer-evaluation"><a href="#Layer-evaluation" class="headerlink" title="Layer evaluation"></a>Layer evaluation</h3><p>Useful layers like BatchNorm-ReLU can have good results in a variety of network architectures. However, as you can see from Figure 4, those layers that perform well in a given architecture may not perform well after migrating to other architectures. In order to significantly improve its generalization performance, the researchers constructed layer search as a multi-objective optimization problem, where each candidate layer is evaluated on K (K&gt; 1) different anchor point architectures to obtain multiple fits value.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1youkct8j30t20dogmu.jpg"></p>
<h3 id="Agent-task-and-anchor-point-architecture"><a href="#Agent-task-and-anchor-point-architecture" class="headerlink" title="Agent task and anchor point architecture"></a>Agent task and anchor point architecture</h3><p>The researchers defined the agent task as an image classification task on the CIFAR-10 data set, and considered three representative network architectures on ImageNet, and adjusted them accordingly to the settings in the article. These architectures include: Pre-activation ResNet50 with a channel multiplier of 0.25×; MobileNetV2 with a channel multiplier of 0.5×; and EfficientNet-B0 with a channel multiplier of 0.5×.</p>
<p>In order to deal with the problem of image resolution lower than ImageNet in CIFAR-10, the first two convolution steps used to reduce the space of the above network architecture are modified to 1. The researchers referred to these adjusted versions as ResNet50-CIFAR, MobileNetV2-CIFAR and EfficientNet-CIFAR.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1ypa2scvj30ra0h8aaz.jpg"></p>
<h3 id="evolution"><a href="#evolution" class="headerlink" title="evolution"></a>evolution</h3><p>The evolutionary algorithm used in this study is a variant of the tournament selection algorithm. In each step, a tournament is constructed based on a random subset of all layers, and the winner can generate a mutant evolutionary version, which is evaluated and added to the candidate layer. Therefore, as this process continues to be repeated, the overall quality of the candidate layer has improved. The researchers also regularize the evolution by keeping the sliding window of the nearest part of the selected layer.</p>
<p>Selection criteria. The selection criteria for tournament winners are not unique, as each tier has multiple points. Two options are shown below:</p>
<p>Average: The layer with the highest average accuracy wins (B in Figure 6);<br>Pareto: The random layer located on the Pareto boundary wins (A, B, and C in Figure 6 all win).</p>
<p>mutation. The researcher completes the calculation graph mutation of the winning layer through the following three steps:</p>
<p>Randomly select intermediate nodes uniformly;<br>Replace the current operation with the new operation in Table 1 randomly and evenly;<br>The new successor of the node is selected uniformly at random.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1ypotj9sj30ki09st8r.jpg"></p>
<h3 id="Veto-mechanism"><a href="#Veto-mechanism" class="headerlink" title="Veto mechanism"></a>Veto mechanism</h3><p>quality. The researcher chooses to discard the layer whose verification accuracy is less than 20% after 100 training steps in any three anchor architectures. Since most of the candidate layers cannot obtain meaningful learning dynamics (see Figure 2), this simple mechanism can ensure that computing resources are concentrated on a small number of potential candidate layers for complete training.</p>
<p>stability. In addition to quality, the researchers also chose to discard layers with numerical instability. The basic principle is: Adversarially adjust the convolution weight θ in the direction of maximizing the network gradient norm, so as to perform stress test on the candidate layer.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/batch-normalization/" rel="tag">batch normalization</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-paper_200927"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/27/paper_200927/"
    >Learning with Noisy Label</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/09/27/paper_200927/" class="article-date">
  <time datetime="2020-09-27T18:50:55.000Z" itemprop="datePublished">2020-09-27</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>Learning with Noisy Label</p>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>Deep learning relies on a large amount of high-quality annotation data-both time and labor costs are high. How to use semi-(weak) supervised learning and unsupervised learning to achieve results equivalent to the level of supervised learning is a very popular research direction.</p>
<p>Learning with noisy label:</p>
<ol>
<li><p>There is a certain amount of labeled data. - It is easy to get through search engines, public data sets, etc.</p>
</li>
<li><p>The quality of the labeling data is not high, and there are high or low labeling errors.</p>
</li>
</ol>
<p>Will not cover unsupervised learning.</p>
<p>Compared with unsupervised learning, learning with noisy label is closer to the landing of deep learning in the industry. The typical status is as follows:</p>
<ol>
<li><p>In the initial stage, there is a certain amount of data with unknown quality.</p>
</li>
<li><p>Generally, there will be continuous manual investment to continuously improve the quality of the label. The form of manual input may be paid crowdsourcing, or it may be through user feedback.</p>
</li>
<li><p>The attention paid to certain labels and certain errors is higher than others and requires targeted optimization.</p>
</li>
</ol>
<h1 id="Core"><a href="#Core" class="headerlink" title="Core"></a>Core</h1><p>Regardless of the method, it is answering a question: how to distinguish between <strong>clean label</strong> and <strong>noisy label</strong>.</p>
<ol>
<li><p>Directly use probability theory models to identify, such as models based on EM algorithms, confidence learning models, etc.</p>
</li>
<li><p>Roughly select the loss predicted by the model and iterate repeatedly.</p>
</li>
<li><p>Implicitly, the model itself is more tolerant of noise. The core idea is to change to weighted sum loss, the weight of noisy is low, and the weight of clean is high. The question is how to find weight.</p>
</li>
</ol>
<h1 id="Theoretical-Foundation"><a href="#Theoretical-Foundation" class="headerlink" title="Theoretical Foundation"></a>Theoretical Foundation</h1><h2 id="Paper【1】"><a href="#Paper【1】" class="headerlink" title="Paper【1】"></a>Paper【1】</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.03530">Understanding deep learning requires rethinking generalization</a></p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1ruu3wiyj30lm07ywez.jpg"></p>
<p>This is the work of the Google brain Samy Bengio group. The viewpoints put forward and proved by experiments: Deep neural networks easily fit random labels. This view is almost a must for noisy label related articles after 2017.</p>
<p>Before this article, the introduction was all about crowdsourcing &amp; mistakes are inevitable, and the SOTA model performed poorly. After this article, the theoretical focus is to solve the overfitting caused by noisy label.</p>
<p>The article also raises a very meaningful question:</p>
<p>The number of parameters of the neural network is greater than the amount of training data. Some models of generalization error are good and some models are poor. What is the difference?</p>
<p>Deep neural networks easily fit random labels</p>
<h3 id="Experimental-program"><a href="#Experimental-program" class="headerlink" title="Experimental program:"></a>Experimental program:</h3><p>Using real data, the label is changed to randomly generated.</p>
<p>model uses the standard model without any modification.</p>
<p>Training effect: training error = 0, test error is the same as the result of random selection.</p>
<h3 id="Explanation-of-the-results"><a href="#Explanation-of-the-results" class="headerlink" title="Explanation of the results:"></a>Explanation of the results:</h3><p>Because the test label is also completely randomly generated, it cannot be predicted. The test error is as expected.</p>
<p>training error = 0, there are many model parameters, and the ability to remember all dataset points.</p>
<p>Random data causes the generalization error of the model to increase significantly.</p>
<h3 id="Comparative-Test"><a href="#Comparative-Test" class="headerlink" title="Comparative Test:"></a>Comparative Test:</h3><p>Based on the original real data set, the label is unchanged, the image pixel is changed to all random, and it can still be 0 training error</p>
<p>Using random + raw data mixed test, the random ratio increases, and the generalization error rate increases. It means that in the case of random data confusion, it still has the ability to learn some real features.</p>
<p>Regularization can reduce testing error, but has no direct effect on generalization error.</p>
<p>Remember the smallest model of all training data.</p>
<p>two-layer ReLU network with p=2n+d parameters can express any labeling of any sample of size n in d dimension.</p>
<p>The 2-layer model can memorize all training data.</p>
<p>explicit regularizers:</p>
<ul>
<li>dropout</li>
<li>weight decay</li>
</ul>
<p>regularization is required to ensure small generalization error</p>
<h2 id="Paper【2】"><a href="#Paper【2】" class="headerlink" title="Paper【2】"></a>Paper【2】</h2><p><a target="_blank" rel="noopener" href="https://www.stat.berkeley.edu/~jordan/638.pdf">Convexity, Classification, and Risk Bounds</a></p>
<p>most loss functions are not completely robust to label noise</p>
<h1 id="Based-on-the-probability-model-estimate-noisy-label"><a href="#Based-on-the-probability-model-estimate-noisy-label" class="headerlink" title="Based on the probability model (estimate noisy label)"></a>Based on the probability model (estimate noisy label)</h1><p>Including EM-based model, belief learning, etc.</p>
<p>The basic mathematical model is:</p>
<ol>
<li><p>Noise is related to label. Lions are easily classified as cats, but not as ships.</p>
</li>
<li><p>Find the joint probability distribution matrix and transition matrix between noisy label and true label.</p>
</li>
<li><p>Use the probability matrix to identify clean label or noise label, and correct the data set.</p>
</li>
</ol>
<h2 id="Paper-1"><a href="#Paper-1" class="headerlink" title="Paper[1]"></a>Paper[1]</h2><p><a target="_blank" rel="noopener" href="https://openreview.net/references/pdf?id=Sk5qglwSl">Training deep neural-networks using a noise adaptation layer</a></p>
<p>Refer to the communication channel model and use the EM algorithm. A bit like the HMM model in NLP.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1rz644doj30se0m40t4.jpg"></p>
<h3 id="Modeling-ideas"><a href="#Modeling-ideas" class="headerlink" title="Modeling ideas:"></a>Modeling ideas:</h3><ul>
<li>The correct unknown label can be viewed as a hidden random variable</li>
<li>Model the noise processes by a communication channel with unknown parameters.</li>
</ul>
<p>Use EM algorithm to find network and correct label. This idea has good articles published in 2012 and 2016.</p>
<p>The typical process is as follows:</p>
<ul>
<li>E-step, estimate the true label</li>
<li>M-step, retrain the network</li>
</ul>
<p>The disadvantage is that each time the label is predicted, the model must be retrained. The idea of improvement is to complete 2 steps end-to-end with a neural network.</p>
<p>In 2014, Sukhbaatar &amp; Fergus proposed to add a constrained linear layer at the end to connect the correct label and noisy label. It is feasible in some scenarios with strong assumptions.</p>
<p>The contribution of this paper is to replace the linear layer added by Sukhbaatar with a softmax layer, which improves the universality of the model.</p>
<h3 id="Author’s-view"><a href="#Author’s-view" class="headerlink" title="Author’s view:"></a>Author’s view:</h3><p>The modified model can be extended to the case where the noise is dependent on both the correct label and the input features.<br>It is suitable for data sets with unknown noisy distribution.</p>
<h2 id="Paper【2】-1"><a href="#Paper【2】-1" class="headerlink" title="Paper【2】"></a>Paper【2】</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.00068">Confident Learning: Estimating Uncertainty in Dataset Labels</a><br>The algorithm principle of the cleanlab library:<br>cleanlab code: <a target="_blank" rel="noopener" href="https://github.com/cgnorthcutt/cleanlab">https://github.com/cgnorthcutt/cleanlab</a><br>Assume that noise is only related to true label and independent of feature.</p>
<h3 id="Core-idea"><a href="#Core-idea" class="headerlink" title="Core idea:"></a>Core idea:</h3><ol>
<li>Through prune, count, rank 3 steps, joint probabilities (true and predicted labels) can be calculated efficiently</li>
<li>Identify label error according to joint probabilities.</li>
</ol>
<p>The theoretical basis is Angluin’s 1988 CNP theory.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1s1l5owzj30lw0e7mxy.jpg"></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution:"></a>Contribution:</h3><p>we prove CL exactly estimates the joint distribution of noisy and true labels with exact identification of label errors under realistic sufficient conditions.<br>The resulting CL procedure is a model-agnostic family of theory and algorithms for characterizing, finding, and learning with label errors. It uses predicted probabilities and noisy labels to count examples in the unnormalized confident joint, estimate the joint distribution, and prune noisy data, producing clean data as output.</p>
<h1 id="Iterative-learning"><a href="#Iterative-learning" class="headerlink" title="Iterative learning"></a>Iterative learning</h1><p>Contains curriculum learning, semi-supervised learning, co-training, self-training. There are too many models of this kind.</p>
<h2 id="Core-idea-1"><a href="#Core-idea-1" class="headerlink" title="Core idea:"></a>Core idea:</h2><ol>
<li>First train a model with large/all data.</li>
<li>According to the loss and other parameters, select the label that is probably true.</li>
<li>Use true label to restart or continue training model.</li>
<li>Repeat steps 2-3.</li>
</ol>
<p>the <strong>difference</strong> lies in:</p>
<ol>
<li>Curriculum learning divides the dataset into N groups at a time, from easy to difficult training. In other large methods, only the simplest group is selected each time.</li>
<li>When repeating training, can the learning goal be more complicated (comprehensive)? Incorporate the parameters learned in the previous round into the learning goal of the new model.</li>
</ol>
<h2 id="Paper【1】-1"><a href="#Paper【1】-1" class="headerlink" title="Paper【1】"></a>Paper【1】</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1712.05055">MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels</a><br>code: <a target="_blank" rel="noopener" href="https://github.com/google/mentornet">https://github.com/google/mentornet</a></p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1s3ccnprj30qm0bqmxw.jpg"></p>
<p><strong>Curriculum learning</strong>, learn from the human learning model. In the order of easy first and then complicated, the learning effect is better and the learning speed is faster. Imagine throwing a random addition and calculus task within 100 to a pupil.</p>
<p>The difficulty lies in how to choose a curriculum?</p>
<p>It can be traced back to Bengio’s introduction of curriculum learning in 2009. Use a predefined fixed curriculum.</p>
<p>The main contributions of this article:</p>
<ul>
<li>Automatically learn data-driven courses. MentorNet learns a data-driven curriculum to supervise the base deep CNN, naely StudentNet.</li>
<li>Based on StudentNet’s feedback, update Curriculum.</li>
</ul>
<p>The paper also gives a more rigorous mathematical model of Curriculum Learning, which is a good reference.<br>Brief summary: in the objective function, there are 3 parameters w, v, lambda.</p>
<p>Among them,</p>
<ul>
<li>w is the weight to be learned by general CNN.</li>
<li>Lambda is a hyperparameter, indicating the difficulty of learning.</li>
<li>v is the weight introduced by curriculum learning, v_i &lt;lambda, which means the i-th data “easy”, participate in this training.</li>
</ul>
<p>It can be seen that lambda and v together define the “course”.</p>
<p>The learning process is: fix v, w in turn, and optimize another parameter.</p>
<p>As the learning progresses, gradually increase the lambda and introduce more and more learning data.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/noisy-label/" rel="tag">noisy label</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-paper_200920_MoCo"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/20/paper_200920_MoCo/"
    >the Second Edition of Momentum Comparison (MoCo)</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/09/20/paper_200920_MoCo/" class="article-date">
  <time datetime="2020-09-20T18:50:55.000Z" itemprop="datePublished">2020-09-20</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>Unsupervised training method of the second edition of momentum comparison (MoCo)</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk0yuxdzo7j30rm07p74g.jpg"></p>
<p>Contrastive unsupervised learning has recently made encouraging progress, such as momentum comparison (MoCo) and SimCLR. In this article, we verify their effectiveness by implementing two design improvements of SimCLR in the MoCo framework. Through a simple modification of MoCo—that is, using an MLP projection head and more data enhancement—we established a stronger benchmark than SimCLR, and does not require a lot of training. We hope this will make the most advanced unsupervised learning research more accessible. The code will be made public.</p>
<p>Recent studies on unsupervised representation learning from images [16,13,8,17,1,9,15,6,12,2] all focus on a central concept, namely contrast learning [5]. The results are very promising: For example, momentum comparison (MoCo) [6] shows that in multiple detection and segmentation tasks, unsupervised pre-training can surpass its image supervision, while SimCLR [2] further reduces unsupervised and The pre-training before supervision indicates the performance gap between the linear classifiers.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk0ywcnbrmj31460qkabf.jpg"></p>
<p>This article describes the establishment of a stronger and more feasible baseline within the MoCo framework. We report two design improvements used in SimCLR, namely an MLP projection head and stronger data enhancement, which are orthogonal to MoCo and SimCLR frameworks. When used with MoCo, they will bring better image classification. And target detection migration learning results. In addition, the MoCo framework can handle a large number of negative samples without the need for a large number of training batches (Figure 1). Compared with the large 4k∼8k batch of SimCLR that requires TPU support, our “MoCo v2” baseline can run on a typical 8-GPU machine and achieve better results than SimCLR. We hope that these improved baselines can provide references for future unsupervised learning research.</p>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><p>Contrastive learning and its latest progress can be seen as training an encoder for dictionary lookup tasks.</p>
<p>Suppose there is a coded query q and a set of coded samples {k0, k1, k2, …}, which are the keys of the dictionary. There is a key (k+) in the dictionary that matches q. The contrast loss is a function whose value is very low when q is similar to its positive key k+ and different from all other keys (the negative key of q). Researchers use the similarity measure of dot product, which is a form of contrast loss function called InfoNCE. This article uses this function:<br>$$<br>\mathcal{L}<em>{q}=-\log \frac{\exp \left(q \cdot k</em>{+} / \tau\right)}{\sum_{i=0}^{K} \exp \left(q \cdot k_{i} / \tau\right)}<br>$$<br>This contrast loss function serves as an unsupervised objective function for training the encoder network that characterizes queries and keys. In general, the query representation is q = f_q(x^q), where f_q is an encoder network, and x^q is the query sample.</p>
<h1 id="Improved-Design"><a href="#Improved-Design" class="headerlink" title="Improved Design"></a>Improved Design</h1><p>SimCLR[2] improves the end-to-end variant of instance recognition in three aspects: (i) larger batch processing (4k or 8k) that can provide more negative samples; (ii) the output fc projection head [ 16] Replaced with MLP header; (3) Data expansion capability is enhanced.</p>
<p>In the MoCo framework, a large number of negative samples are readily available; the instantiation methods of MLP header and data expansion and contrast learning are orthogonal. Next, we study these improvements in MoCo.</p>
<h1 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h1><p>Unsupervised learning is performed on the 1.28M ImageNet[3] training set. (i) ImageNet linear classification: freeze the features and train a supervised linear classifier; we report 1 crop (224×224), which ranks first in verification accuracy. (ii) Migrating to VOC target detection [4]: Faster R-CNN detector [14] (c4-backbone) on the VOC 07+12 training set for all entries (including supervision and MoCo v1 baseline) End fine-tuning, we make 24k iterative fine-tuning of VOC, which is higher than the 18k in [6]. And use the COCO standard [10] for evaluation on the VOC 07 test set. We use the same hyperparameters (unless otherwise noted) and code base as MoCo [6]. All results use standard size ResNet-50 [7].</p>
<p>MLP header After [2], we replaced the fc header in MoCo with a 2-layer MLP header (hidden layer 2048-d, using ReLU). Note that this only affects the unsupervised training phase; this MLP header is not used in the linear classification or migration phase. [2] After that, we look for the best τ for the accuracy of ImageNet linear classification:</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk0yyll6idj30hp0303yf.jpg"></p>
<p>Using the default τ = 0.07[16,6], the trained MLP head is improved from 60.6% to 62.9%; switching to the optimal value of MLP (0.2), the accuracy is improved to 66.2%. Table 1(a) shows its detection results: Compared with the big leap on ImageNet, the detection gain is smaller.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk0yz83zo5j30i70acgmc.jpg"></p>
<p>Data enhancement We extend the original enhancement in [6] by adding blur enhancement in [2] (we found that the stronger color distortion in [2] has diminishing gain in our higher baseline). A separate addition (ie (no MLP)) increased the MoCo baseline on ImageNet by 2.8% to 63.4%, as shown in Table 1(b). Interestingly, its detection accuracy is higher than that of using MLP alone, Table 1 (b) and (a), although the linear classification accuracy is much lower (63.4% vs. 66.2%). This shows that the linear classification accuracy and the migration performance in detection are not monotonously related. For MLP, the additional enhancement will be the ImageNet The accuracy is improved to 67.3%, see Table 1(c).</p>
<p>Comparison with SimCLR Table 2 compares SimCLR [2] with our result MoCo v2. For fair comparison, we also studied a cosine (half-period) learning rate scheduling adopted by SimCLR [11]. Table 1 (d, e). MoCo v2 uses 200 epochs and 256 batch sizes for pre-training, and achieves 67.5% accuracy on ImageNet, which is 5.6% higher than SimCLR’s accuracy under the same epoch and batch size, and 66.6% higher than SimCLR’s large batch results. . Through 800-epoch pre-training, MoCo v2 reached 71.1%, surpassing SimCLR’s 69.3%, reaching 1000 epochs.</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk0yzlfqmcj30la0j2gn7.jpg"></p>
<h1 id="Computing-costs"><a href="#Computing-costs" class="headerlink" title="Computing costs"></a>Computing costs</h1><p>In Table 3, we report the realized memory and time costs. The end-to-end case reflects the cost of SimCLR in the GPU (instead of the TPUs in [2]). Even on high-end 8-GPU machines, 4k batch sizes are difficult to handle. Moreover, with the same batch size of 256, the end-to-end variant is still more expensive in memory and time, because it propagates backwards to the q and k encoders, while MoCo only propagates backwards to the q encoders .</p>
<p>Table 2 and Table 3 show that in order to obtain good accuracy, a large training batch is not required. The improvement we researched only requires a few lines of code changes to MoCo v1, and we will make the code public for future research.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-paper_200913"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/13/paper_200913/"
    >A Neural Probabilistic Language Model</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/09/13/paper_200913/" class="article-date">
  <time datetime="2020-09-13T18:50:55.000Z" itemprop="datePublished">2020-09-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>A Neural Probabilistic Language Model</p>
<p>An old but significant paper, A Neural Probabilistic Language Model. The author is Professor Yoshua Bengio from the University of Montreal, one of the founders of deep learning technology.</p>
<p>This article first used neural networks to solve language model problems in 2003. Although it did not receive much attention at the time, it laid a solid foundation for deep learning to solve language model problems and even many other nlp problems. Later generations stood on the shoulders of Yoshua Bengio and made more achievements. Including Word2Vec author Tomas Mikolov proposed RNNLM and later Word2Vec on the basis of NNLM. The article also earlier proposed that word represents a low-rank vector instead of one-hot. As a by-product of a language model, word embedding played a key role in the subsequent research, providing researchers with a broader idea.</p>
<p>The biggest contribution of this paper is to construct a language model with a multilayer perceptron (MLP), as shown in the figure below:<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjw2a07b2lj30rg0ipaav.jpg"></p>
<p>The model has three layers. The first layer is a mapping layer, which maps n words to the corresponding word embeddings. In fact, this layer is the input layer of MLP; the second layer is the hidden layer, and the activation function uses tanh; the third layer is The output layer, because it is a language model, needs to predict the next word based on the first n words, so it is a multi-classifier, using softmax. The largest amount of calculation in the entire model is concentrated on the last layer, because in general, the vocabulary is large, and the conditional probability of each word needs to be calculated, which is the calculation bottleneck of the entire model.</p>
<p>Here, it should be noted that a word embedding matrix needs to be initialized in advance, and each row represents a word vector. The word vector is also a training parameter, which is updated in each training. It can be seen here that the word vector is an adjunct of the language model, because the language model itself is to estimate how much a given sentence is like a human word, but later studies have found that the language model has become a very good tool .</p>
<p>Softmax is a very inefficient processing method. It needs to calculate the probability of each word first, and also calculate the exponent. The exponent is approximated by a series in the computer. The calculation complexity is very high, and finally the normalization is performed. deal with. Since then, many studies have been optimized for this problem, such as hierarchical softmax, such as softmax tree.</p>
<p>Of course, the effect of NNLM does not seem to be much at present, but it has very important significance for subsequent related research. The Future Work in the article mentioned that using RNN instead of MLP as a model may achieve better results, which was verified in the doctoral thesis of Tomas Mikolov later, which was later RNNLM.</p>
<p>So we have caught up with a good era, and we can stand on the shoulders of giants and see a farther future.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-paper_200906_matchnetwork"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/06/paper_200906_matchnetwork/"
    >Matching Networks for One Shot Learning</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/09/06/paper_200906_matchnetwork/" class="article-date">
  <time datetime="2020-09-06T18:50:55.000Z" itemprop="datePublished">2020-09-06</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.04080">Matching Networks for One Shot Learning</a></p>
<p><em>This article accounts for my first exposure to a new field in learning.</em></p>
<p>Something about “one-shot” learning, that is, learning from one (or very few) sample instead of the large data sets. After all, a child can know what a giraffe is through a picture, but the machine needs a lot of samples!</p>
<p>Matching Networks for One Shot Learning This paper is a paper from Google DeepMind, which is mainly to solve: learn classification based on small samples (or other tasks), and this trained model does not need to be adjusted, and can also be used Categorize the categories that have not appeared in the training process (there may be some twists here, and I will explain in detail later in conjunction with the symbol definition. In fact, I personally feel that this task also has a feeling of “transfer learning”).</p>
<h1 id="Idea"><a href="#Idea" class="headerlink" title="Idea:"></a>Idea:</h1><p>Train an end-to-end classifier similar to nearest neighbor. The reason why it is similar is because although the overall idea is very similar, for NN, the sample is what the input is, but here you need to learn a sample from the sample The representations, encode them.</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjw20pn1gqj30fj0ar74m.jpg"></p>
<h1 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h1><p>Training process: Given a support set $S=\left{\left(x_{i}, y_{i}\right)\right}<em>{i=1}^{k}$ with k samples, classify the test samples $\hat{x}$ (classification, because the category of $\hat{x}$ is the same as one or several sample categories in S), The category is $C</em>{S}(\hat{x})$.</p>
<p>Definition $S \rightarrow C_{S}(\hat{x})$ this mapping is $P(\hat{y} \mid \hat{x}, S)$, where the parameters of P are learned through neural networks, and the mapping method is the last model we learned.</p>
<p>Therefore, in the testing process: Given a new support set $S^{\prime}$, we can use the model learned before to obtain their possible label $\hat{x}$ for each test sample $\hat{y}$.</p>
<p>For example, given a picture of a Siamese cat and a picture of Corgi as S during training, a new husky picture model can be classified as a dog; in the test, a picture of Xiong Er and A picture of Bugs Bunny and another picture of Winnie the Pooh and ask the machine which category the new picture belongs to, and the machine will tell you that this is a bear (it’s the same category as that bear)</p>
<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm:"></a>Algorithm:</h1><p>Given a test sample $\hat{x}$, the process of calculating $\hat{y}$ is very similar to Nearest Neighbors:<br>$$<br>\hat{y}=\sum_{i=1}^{k} a\left(\hat{x}, x_{i}\right) y_{i}<br>$$<br>Here a is similar to the kernel function in the attention model, which is used to measure the matching degree between $\hat{x}$ and training sample $x_i$, and then the calculation of the test sample label through $y_i$ is similar to weighted summation:<br>$$<br>a\left(\hat{x}, x_{i}\right)=e^{c\left(f(\hat{x}), g\left(x_{i}\right)\right)} / \sum_{j=1}^{k} e^{c\left(f(\hat{x}), g\left(x_{j}\right)\right)}<br>$$<br>Here, the formula f defines how to encode the test sample into a vector, and the formula g defines how to encode the training sample. From c(), the cos distance is used to calculate the matching degree between the two, and then they are normalized by a softmax.</p>
<h1 id="Encode-the-training-set-function-g"><a href="#Encode-the-training-set-function-g" class="headerlink" title="Encode the training set (function g)"></a>Encode the training set (function g)</h1><p>The structure of g is a two-way LSTM. The input sequence of this two-way LSTM is each sample $\left(x_{0}, x_{1}, x_{2} \ldots\right)$ in S. $g^{\prime}\left(x_{i}\right)$ is an encoding that first inputs $x_i$ to a neural network (such as VGG, Inception model).</p>
<p>The definition is based on the support set S, and the coding of the sample $x_i$ is:<br>$$<br>g\left(x_{i}, S\right)=\overrightarrow{h_{i}}+\overline{h_{i}}+g^{\prime}\left(x_{i}\right)<br>$$<br>where<br>$$<br>\begin{aligned}<br>\vec{h}<em>{i}, \vec{c}</em>{i} &amp;=\operatorname{LSTM}\left(g^{\prime}\left(x_{i}\right), \vec{h}<em>{i-1}, \vec{c}</em>{i-1}\right) \<br>\stackrel{\leftarrow}{h}<em>{i}, \bar{c}</em>{i} &amp;=\operatorname{LSTM}\left(g^{\prime}\left(x_{i}\right), \bar{h}<em>{i+1}, \bar{c}</em>{i+1}\right)<br>\end{aligned}<br>$$</p>
<p>$h_i$ and $c_i$ are both the output of LSTM. If you don’t know much about it, you can take a look at the LSTM algorithm. In addition, the original text did not mention how to sort the unordered reference set samples, but refer to another article of the author: Order Matters: Sequence to Sequence for Sets. It is found that the original unordered support set sample sets are sorted here .</p>
<p>Some people may wonder why LSTM is used. Models like LSTM and RNN have to remember something, but the categories of these samples are different, so what do you want to remember? My understanding is that the samples of each category are input into the LSTM as a sequence, so that the model looks at all the samples to automatically select the appropriate features to measure. For example, if our goal is to recognize faces, then we need to construct a distance function. To strengthen the appropriate features (such as hair color, face shape, etc.); and if our goal is to recognize posture, then we need to build a distance function that captures the similarity of posture. Here we need to refer to Metric Learning.</p>
<h1 id="Encode-the-test-set-function-f"><a href="#Encode-the-test-set-function-f" class="headerlink" title="Encode the test set (function f)"></a>Encode the test set (function f)</h1><p>f is an iterative LSTM with K steps (note that k here is k steps, and k above is k samples), and all training samples ($g\left(x_{i}\right)$) are considered in the process of encoding the test set, and finally f The encoding result of is the hidden state output by the last LSTM.<br>$$<br>\begin{aligned} f(\hat{x}, S) &amp;=\operatorname{attLSTM}\left(f^{\prime}(\hat{x}), g(S), K\right) \ \hat{h}<em>{k}, c</em>{k} &amp;=\operatorname{LSTM}\left(f^{\prime}(\hat{x}),\left[h_{k-1}, r_{k-1}\right], c_{k-1}\right) \ h_{k} &amp;=\hat{h}<em>{k}+f^{\prime}(\hat{x}) \ r</em>{k-1} &amp;=\sum_{i=1}^{|S|} a\left(h_{k-1}, g\left(x_{i}\right)\right) g\left(x_{i}\right) \ a\left(h_{k-1}, g\left(x_{i}\right)\right) &amp;=\operatorname{softmax}\left(h_{k-1}^{T} g\left(x_{i}\right)\right) \end{aligned}<br>$$</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/one-shot/" rel="tag">one shot</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-shallow_GCN"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/01/shallow_GCN/"
    >First Encounter with GCN</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/09/01/shallow_GCN/" class="article-date">
  <time datetime="2020-09-01T15:50:55.000Z" itemprop="datePublished">2020-09-01</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/shallow-understanding/">shallow understanding</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="Intorduction"><a href="#Intorduction" class="headerlink" title="Intorduction"></a>Intorduction</h2><p>Graph Convolutional Network(GCN), has been very popular in the past two years and has made a lot of progress.</p>
<p>Recently, Professor Maosong Sun’s group of Tsinghua University published the paper Graph Neural Networks: A Review of Methods and Applications on arXiv. The author gave a detailed and comprehensive overview of the existing GNN models. GCN is an important branch of GNN.</p>
<h2 id="What-is-Convolution"><a href="#What-is-Convolution" class="headerlink" title="What is Convolution?"></a>What is Convolution?</h2><p>The mathematical definition of Convolution is:<br>$$<br>(f * g)(t)=\int_{\mathbb{R}} f(x) g(t-x) d x<br>$$<br>Generally called g is the filter or kernel acting on f<br>The one-dimensional convolution diagram is as follows:<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjqrco4cr7g30d004376b.gif"></p>
<p>The common CNN two-dimensional convolution diagram is as follows:<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjqrd8bnvkg30az0chq6a.gif"></p>
<p>The concept of convolution in an image is very straightforward, because the arrangement order of pixels has a clear up, down, left, and right positional relationship.</p>
<p><strong>How to do convolution in the abstract graph?</strong></p>
<h2 id="Fourier-Transform"><a href="#Fourier-Transform" class="headerlink" title="Fourier Transform"></a>Fourier Transform</h2><p>In order to solve the problem of convolution calculation on graph, we give the second equipment-Fourier transform.</p>
<p>First of all, according to the convolution theorem, the convolution formula can also be written as:<br>$$<br>f * g=\mathcal{F}^{-1}{\mathcal{F}{f} \cdot \mathcal{F}{g}}<br>$$<br>In this way, we only need to define the fourier transformation on the graph to define the convolution transformation on the graph.</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjqrfjkvkag30b408c786.gif"></p>
<p>Okay, let’s first look at the definition of Fourier transform:<br>$$<br>\mathcal{F}{f}(v)=\int_{\mathbb{R}} f(x) e^{-2 \pi i x \cdot v} d x<br>$$<br>The Inverse Fourier transform is:<br>$$<br>\mathcal{F}^{-1}{f}(x)=\int_{\mathbb{R}} f(v) e^{2 \pi i x \cdot v} d v<br>$$</p>
<p>According to the definition of Fourier transform and its inverse transform, let’s prove the <strong>convolution theorem</strong>.<br>$$<br>\begin{aligned}<br>h(z) &amp;=\int_{\mathbb{R}} f(x) g(z-x) d x \<br>\mathcal{F}{f * g}(v) &amp;=\mathcal{F}{h}(v) \<br>&amp;=\int_{\mathbb{R}} h(z) e^{-2 \pi i z \cdot v} d z \<br>&amp;=\int_{\mathbb{R}} \int_{\mathbb{R}} f(x) g(z-x) e^{-2 \pi i z \cdot v} d x d z \<br>&amp;=\int_{\mathbb{R}} f(x)\left(\int_{\mathbb{R}} g(z-x) e^{-2 \pi i z \cdot v} d z\right) d x<br>\end{aligned}<br>$$<br>where $y=z-x ; d y=d z$<br>$$<br>\begin{aligned}<br>\mathcal{F}{f * g}(v) &amp;=\int_{\mathbb{R}} f(x)\left(\int_{\mathbb{R}} g(y) e^{-2 \pi i(y+x) \cdot v} d y\right) d x \<br>&amp;=\int_{\mathbb{R}} f(x) e^{-2 \pi i x \cdot v}\left(\int_{\mathbb{R}} g(y) e^{-2 \pi i y \cdot v} d y\right) d x \<br>&amp;=\int_{\mathbb{R}} f(x) e^{-2 \pi i x \cdot v} d x \int_{\mathbb{R}} g(y) e^{-2 \pi i y \cdot v} d y \<br>&amp;=\mathcal{F}{f}(v) \cdot \mathcal{F}{g}(v)<br>\end{aligned}<br>$$<br>Finally, act $\mathcal{F}^{-1}$ on both sides of the equation at the same time to get</p>
<h2 id="Laplacian-Operator"><a href="#Laplacian-Operator" class="headerlink" title="Laplacian Operator"></a>Laplacian Operator</h2><p>After a wave of unrest, another unfamiliar concept came.<br>Don’t worry, this is the last piece of equipment before the <em>Novice Village</em>.<br>The first derivative is defined as:<br>$$<br>f^{\prime}(x)=\lim <em>{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}<br>$$<br>The laplacian operator is simply the second derivative:<br>$$<br>\Delta f(x)=\lim <em>{h \rightarrow 0} \frac{f(x+h)-2 f(x)+f(x-h)}{h^{2}}<br>$$<br>On the graph, we can define the first derivative as:<br>$$<br>f</em>{* g}^{\prime}(x)=f(x)-f(y)<br>$$<br>Where y is the neighbor node of x<br>Then the corresponding Laplacian operator can be defined as:<br>$$<br>\Delta</em>{* g} f^{\prime}(x)=\Sigma_{y \sim x} f(x)-f(y)<br>$$<br>Define $D$ to be the degree matrix of $N \times N$<br>$$<br>D(i, j)=\left{\begin{array}{ll}<br>d_{i} &amp; \text { if } i=j \<br>0 &amp; \text { otherwise }<br>\end{array}\right.<br>$$<br>Defice $A$ to be the adjacency matrix of  $N \times N$<br>$$<br>A(i, j)=\left{\begin{array}{ll}<br>1 &amp; \text { if } x_{i} \sim x_{j} \<br>0 &amp; \text { otherwise }<br>\end{array}\right.<br>$$<br>Then the Laplacian operator on the graph can be written as<br>$$<br>L=D-A<br>$$<br>After standardization $L=I_{N}-D^{-\frac{1}{2}} A D^{-\frac{1}{2}}$</p>
<h2 id="Derive-Graph-Convolution"><a href="#Derive-Graph-Convolution" class="headerlink" title="Derive Graph Convolution"></a>Derive Graph Convolution</h2><p>Now that we have obtained all the equipment of Novice Village, we will start to derive the GCN formula below. Remember the convolution theorem we mentioned earlier?<br>$$<br>f * g=\mathcal{F}^{-1}{\mathcal{F}{f} \cdot \mathcal{F}{g}}<br>$$<br>Then the convolution formula of the graph can be expressed as:<br>$$<br>g * x=U\left(U^{T} g \cdot U^{T} x\right)<br>$$<br>As the filter function of graph convolution, we hope to have good locality. Just like the filter in the CNN model, it only affects pixels near one pixel. Then we can define as a function of laplacian matrix<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gju5ppjvdlg30fk0bon4f.gif"><br>Applying the laplacian matrix once is equivalent to spreading neighbor nodes on the graph once. Further we can regard $U^{T} g$ as a function of the laplacian eigenvalue of $g_{\theta}(\Lambda)$.<br>Rewriting the above graph convolution formula, we can get the formula (3) of the paper <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1609.02907.pdf">SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a><br>$$<br>g_{\theta} * x=U g_{\theta} U^{T} x=U g_{\theta^{\prime}}(\Lambda) U^{T} x<br>$$<br>It can be seen that the complexity of this convolution calculation is very high, involving finding the eigenvector of the laplacian matrix and a large number of matrix calculations. Below we consider approximating the filter function, the goal is to save the solution of the feature vector<br>$$<br>g_{\theta^{\prime}}(\Lambda) \approx \sum_{k=0}^{K} \theta_{k}^{\prime} T_{k}(\tilde{\Lambda})<br>$$<br>Where $T_{k}$ is the Chebyshev polynomial. Here, simple $g_{\theta}(\Lambda)$ can be simply regarded as a polynomial of $(\Lambda)$.<br>Because $U \Lambda^{k} U^{T}=\left(U \Lambda U^{T}\right)^{k}=L^{k}$, so the filter function above can be written as a function of L<br>$$<br>g_{\theta^{\prime}}(\Lambda) \approx \sum_{k=0}^{K} \theta_{k}^{\prime} T_{k}(\tilde{L})<br>$$<br>Set K=1 and the convolution formula can be simplified to<br>$$<br>\begin{aligned}<br>g_{\theta^{\prime}} * x &amp; \approx \theta\left(I_{N}+L\right) x \<br>&amp;=\theta\left(I_{N}+D^{-\frac{1}{2}} A D^{-\frac{1}{2}}\right) x<br>\end{aligned}<br>$$<br>Assume that $\tilde{A}=A+I_{N}, \quad \tilde{D}<em>{i i}=\sum</em>{j} \tilde{A}<em>{i j}$,<br>$$<br>g</em>{\theta^{\prime}} * x=\theta\left(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}\right) x<br>$$<br>Then coupled with the activation layer, we can get the final GCN formula:<br>$$<br>H^{(l+1)}=\sigma\left(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(l)} W^{(l)}\right)<br>$$</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GCN/" rel="tag">GCN</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-paper_200830_GAN"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/08/30/paper_200830_GAN/"
    >Review on GAN</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/08/30/paper_200830_GAN/" class="article-date">
  <time datetime="2020-08-30T18:50:55.000Z" itemprop="datePublished">2020-08-30</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/paper-reading/">paper reading</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>The most comprehensive review of GAN in history 2020 edition: algorithms, theories and applications.<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2001.06937.pdf">A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications</a></p>
<p><em>Since I had a project on GAN, I explored deeply about various GAN.</em></p>
<p>In recent years, Generative Adversarial Networks (GAN) has been a hot research topic. Since 2014, researchers have conducted extensive research on GAN and proposed a large number of algorithms. However, there are few comprehensive studies to explain the connections between different GAN variants and the way they evolved. In this article, we try to review a variety of GAN methods from the perspectives of algorithms, theory, and applications. First, we introduced in detail the research motivation, mathematical representation and architecture of most GAN algorithms. In addition, GAN has been combined with other machine learning algorithms in some specific applications, such as semi-supervised learning, transfer learning and reinforcement learning. This article compares the similarities and differences of these GAN methods. Secondly, we studied the theoretical issues related to GAN. Third, we explained the typical applications of GAN in image processing and computer vision, natural language processing, music, speech and audio, medicine, and data science. Finally, we pointed out some future open research issues for GAN.</p>
<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h1><p>In this section, we first introduce the most primitive GAN. Then, introduce its representative variants, training and evaluation methods, and task-driven GAN.</p>
<h2 id="Generative-confrontation-network"><a href="#Generative-confrontation-network" class="headerlink" title="Generative confrontation network"></a>Generative confrontation network</h2><p>When the models are all neural networks, the GAN architecture is very intuitive to implement. In order to learn the distribution p_g of the generator on the data x, first define a prior distribution p_z(z)[3] about the input noise variable, where z is the noise variable. Next, GAN represents the mapping from noise space to data space G(z, θ_g), where G is a differentiable function represented by a neural network with a parameter θ_g. In addition to G, another neural network D(x, θ_d) is also defined by the parameter θ_d, and the output of D(x) is a scalar. D(x) represents the probability that x comes from the real data instead of from the generator G. We train the discriminator D to maximize the probability of providing the correct label for the training data and the fake samples generated by the generator G. At the same time, we train G to minimize log(1-D(G(z))).</p>
<h3 id="Objective-function"><a href="#Objective-function" class="headerlink" title="Objective function"></a>Objective function</h3><p>GAN can use a variety of different objective functions.</p>
<h4 id="The-most-primitive-minimax-game"><a href="#The-most-primitive-minimax-game" class="headerlink" title="The most primitive minimax game"></a>The most primitive minimax game</h4><p>The objective function of GAN [3] is<br>$$<br>\begin{array}{l}<br>\min <em>{G} \max <em>{D} V(D, G)=E</em>{x \sim p</em>{\text {data}}(x)}[\log D(x)] \<br>\quad+E_{z \sim p_{z}(z)}[\log (1-D(G(z)))]<br>\end{array}<br>$$<br>Where D(x) is the cross entropy between $[1, 0]^{T}$ and $[D(x), 1-D(x)]^T$. Similarly, log(1-D(G(z))) is the cross entropy between $[0, 1]^T$ and $[D(G(z)), 1-D(G(z))]^T$. For a fixed G, the optimal discriminator D is given in [3]:<br>$$<br>D_{G}^{<em>}(x)=\frac{p_{\text {data}}(x)}{p_{\text {data}}(x)+p_{g}(x)}<br>$$<br>The mini-max game in the formula can be reformulated as:<br>$$<br>\begin{array}{l}<br>C(G)=\max <em>{D} V(D, G) \<br>=E</em>{x \sim p_{\text {data}}}\left[\log D_{G}^{</em>}(x)\right] \<br>\quad+E_{z \sim p_{z}}\left[\log \left(1-D_{G}^{<em>}(G(z))\right)\right] \<br>=E_{x \sim p_{\text {data}}}\left[\log D_{G}^{</em>}(x)\right]+E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{*}(x)\right)\right] \<br>=E_{x \sim p_{\text {data}}}\left[\log \frac{p_{\text {data}}(x)}{\frac{1}{2}\left(p_{\text {data}}(x)+p_{g}(x)\right)}\right] \<br>\quad+E_{x \sim p_{g}}\left[\frac{p_{g}(x)}{\frac{1}{2}\left(p_{\text {data}}(x)+p_{g}(x)\right)}\right]-2 \log 2<br>\end{array}<br>$$<br>The KL divergence and JS divergence between two probability distributions p(x) and q(x) are defined as follows:<br>$$<br>K L(p | q)=\int p(x) \log \frac{p(x)}{q(x)} d x<br>$$<br>$$<br>J S(p | q)=\frac{1}{2} K L\left(p | \frac{p+q}{2}\right)+\frac{1}{2} K L\left(q | \frac{p+q}{2}\right)<br>$$<br>$$<br>\begin{array}{l}<br>C(G)=K L\left(p_{\text {data}} | \frac{p_{\text {data}}+p_{g}}{2}\right)+K L\left(p_{g} | \frac{p_{\text {data}}+p_{g}}{2}\right)-2 \log 2 \<br>=2 J S\left(p_{\text {data}} | p_{g}\right)-2 \log 2<br>\end{array}<br>$$<br>Therefore, the objective function of GAN and KL divergence are related to JS divergence.</p>
<h4 id="Unsaturated-game"><a href="#Unsaturated-game" class="headerlink" title="Unsaturated game"></a>Unsaturated game</h4><p>In fact, formula may not provide a large enough gradient for G to learn well. Generally speaking, G has poor performance in the early stages of the learning process, and the generated samples are significantly different from the training data. Therefore, D can reject the samples generated by G with high confidence. In this case, log(1-D(G(z))) is saturated. We can train G to maximize log(D(G(z))) instead of minimizing log(1-D(G(z))). The loss of the generator becomes<br>$$<br>\begin{array}{l}<br>J^{(G)}=E_{z \sim p_{z}(z)}[-\log (D(G(z)))] \<br>=E_{x \sim p_{g}}[-\log (D(x))]<br>\end{array}<br>$$<br>This new objective function can make D and G reach the same fixed point during the training process, but provides a much larger gradient in the early stage of learning. Unsaturated games are heuristic, not theory-driven. However, there are other problems in the unsaturated game, such as the unstable numerical gradient used to train G. Under the optimal D<em><em>G, there are<br>$$<br>\begin{array}{l}<br>E</em>{x \sim p_{g}}\left[-\log \left(D_{G}^{</em>}(x)\right)\right]+E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{<em>}(x)\right)\right] \<br>=E_{x \sim p_{g}}\left[\log \frac{\left(1-D_{G}^{</em>}(x)\right)}{D_{G}^{<em>}(x)}\right]=E_{x \sim p_{g}}\left[\log \frac{p_{g}(x)}{p_{\text {data}}(x)}\right] \<br>=K L\left(p_{g} | p_{\text {data}}\right)<br>\end{array}<br>$$<br>Therefore E_(x~p_g)[-log(D</em><em>G(x))] is equivalent to<br>$$<br>\begin{array}{l}<br>E</em>{x \sim p_{g}}\left[-\log \left(D_{G}^{<em>}(x)\right)\right] \<br>=K L\left(p_{g} | p_{\text {data}}\right)-E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{</em>}(x)\right)\right]<br>\end{array}<br>$$<br>$$<br>\begin{array}{l}<br>E_{x \sim p_{\text {data}}}\left[\log D_{G}^{<em>}(x)\right]+E_{x \sim p_{g}}\left[\log \left(1-D_{G}^{</em>}(x)\right)\right] \<br>=2 J S\left(p_{\text {data}} | p_{g}\right)-2 \log 2<br>\end{array}<br>$$<br>Therefore E_(x~p_g)[log^(1-D<em><em>G(x))] is equivalent to<br>$$<br>\begin{array}{l}<br>E</em>{x \sim p_{g}}\left[\log \left(1-D_{G}^{</em>}(x)\right)\right] \<br>=2 J S\left(p_{\text {data}} | p_{g}\right)-2 \log 2-E_{x \sim p_{\text {data}}}\left[\log D_{G}^{<em>}(x)\right]<br>\end{array}<br>$$<br>Finally we get<br>$$<br>\begin{array}{l}<br>E_{x \sim p_{g}}\left[-\log \left(D_{G}^{</em>}(x)\right)\right] \<br>=K L\left(p_{g} | p_{\text {data}}\right)-2 J S\left(p_{\text {data}} | p_{g}\right)+ \<br>E_{x \sim p_{\text {data}}}\left[\log D_{G}^{*}(x)\right]+2 \log 2<br>\end{array}<br>$$<br>It can be seen from the above formula that the optimization of the alternative G loss function in the unsaturated game is contradictory, because the first goal is to make the difference between the generated distribution and the actual distribution as small as possible, and because of the existence of the negative sign The second goal is to make the difference between these two distributions as large as possible. This will bring unstable numerical gradients for training G. In addition, KL divergence is an asymmetric measure, which can be reflected in the following two examples<br>$$<br>\begin{aligned}<br>&amp;\text { If } p_{\text {data}}(x) \rightarrow 0 \text { and } p_{g}(x) \rightarrow 1, \text { we have }\<br>&amp;K L\left(p_{g} | p_{d a t a}\right) \rightarrow+\infty\<br>&amp;\text { If } p_{\text {data}}(x) \rightarrow 1 \text { and } p_{g}(x) \rightarrow 0, \text { we have }\<br>&amp;K L\left(p_{g} | p_{d a t a}\right) \rightarrow 0<br>\end{aligned}<br>$$<br>The penalties for the two errors of G are completely different. The first error is that G produces unreal samples, and the corresponding penalty is large. The second type of error is that G fails to produce real samples, and the penalty is small. The first type of error is that the generated samples are inaccurate, and the second type of error is that the generated samples are not diverse enough. Based on this principle, G tends to generate repeated but safe samples, rather than risk generating different but unsafe samples, which will lead to the problem of mode collapse.</p>
<h4 id="Maximum-likelihood-game"><a href="#Maximum-likelihood-game" class="headerlink" title="Maximum likelihood game"></a>Maximum likelihood game</h4><p>In GAN, there are many ways to approximate first equation. Assuming that the discriminator is optimal, we want to minimize<br>$$<br>\begin{array}{l}<br>J^{(G)}=E_{z \sim p_{z}(z)}\left[-\exp \left(\sigma^{-1}(D(G(z)))\right)\right] \<br>=E_{z \sim p_{z}(z)}[-D(G(z)) /(1-D(G(z)))]<br>\end{array}<br>$$<br>There are other possible methods to approach the maximum likelihood in the GAN framework [17]. Figure 1 shows the comparison between the original zero-sum game, the unsaturated game, and the maximum likelihood game.<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjw1nv4taaj30g00k2762.jpg"><br>From Figure 1, three observations can be obtained.</p>
<p>First, when the sample may come from the generator, that is, at the left end of the graph, both the maximum likelihood game and the original minimax game are affected by gradient dispersion, while heuristic unsaturated games do not have this problem.</p>
<p>Second, there is a problem with the maximum likelihood game, that is, almost all gradients come from the right end of the curve, which means that only a small part of the samples in each minibatch dominate the calculation of the gradient. This shows that the method of reducing sample variance may be an important research direction to improve the performance of GAN based on maximum likelihood game.</p>
<p>Third, the sample variance of the heuristic-based unsaturated game is low, which may be the possible reason for its more successful application in practical applications.</p>
<p>M.Kahng et al. [124] proposed GAN Lab, which provides an interactive visualization tool for non-professionals to learn GAN and do experiments. Bau et al. [125] proposed an analysis framework to visualize and understand GAN.</p>
<h2 id="Representative-GAN-variants"><a href="#Representative-GAN-variants" class="headerlink" title="Representative GAN variants"></a>Representative GAN variants</h2><p>There are many papers related to GAN [126]-[131], such as CSGAN [132] and LOGAN [133]. In this section, we will introduce some representative GAN variants.</p>
<ol>
<li>InfoGAN</li>
<li>ConditionalGANs(cGANs)</li>
<li>CycleGAN</li>
<li>f-GAN</li>
<li>IntegralProbabilityMetrics(IPMs) </li>
<li>LossSensitiveGAN(LS-GAN)</li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjw1p5v1ezj30g0048jre.jpg"></p>
<h2 id="GAN-training"><a href="#GAN-training" class="headerlink" title="GAN training"></a>GAN training</h2><p>Although there are unique solutions in theory, for many reasons [29], [32], [179], GAN training is difficult and often unstable. One of the difficulties comes from the fact that the optimal weight of GAN corresponds to the saddle point of the loss function, not the minimum point.</p>
<p>There are many papers on GAN training. Yadav et al. [180] used prediction methods to make GAN training more stable. [181] By using independent learning rates, two time scale update rules (TTUR) are proposed for the discriminator and generator to ensure that the model can converge to a stable local Nash equilibrium. Arjovsky [179] conducted a theoretical study to fully understand the training dynamics of GAN, analyzed why GAN is difficult to train, studied and strictly proved the saturation and instability of the loss function when training GAN, and proposed a solution A practical and theoretical direction for this kind of problems, and new tools are introduced to study them. Liang et al. [182] believe that the training of GAN is a continuous learning problem [183].</p>
<p>One way to improve GAN training is to evaluate the empirical “symptoms” that may occur during training. These symptoms include: the generator collapses to the extent that it can only generate extremely similar samples for different inputs [29]; the discriminator loss quickly converges to zero [179], and it cannot provide gradient updates for the generator; making the generator and discriminator be the same It is difficult for the model to converge [32].</p>
<h2 id="GAN-evaluation-index"><a href="#GAN-evaluation-index" class="headerlink" title="GAN evaluation index"></a>GAN evaluation index</h2><p>In this section, we explain some evaluation indicators used in GAN [215], [216]:</p>
<ol>
<li>InceptionScore(IS)</li>
<li>Modescore(MS)</li>
<li>FrechetInceptionDistance(FID)</li>
<li>Multi-scalestructuralsimilarity(MS-SSIM)</li>
</ol>
<p>How to choose a good evaluation index for GAN is still a difficult problem [225]. Xu et al. [219] proposed an empirical study on GAN evaluation indicators. Karol Kurach [224] conducted a large-scale research on regularization and normalization in GAN. There are other comparative studies on GAN, such as [226]. References [227] proposes several metrics as meta-metrics to guide researchers in choosing quantitative evaluation indicators. Appropriate evaluation indicators should distinguish real samples from generated fake samples, verify mode drop or mode collapse, and detect overfitting. Hope there will be a better way to evaluate the quality of GAN models in the future.</p>
<h2 id="Task-driven-GAN"><a href="#Task-driven-GAN" class="headerlink" title="Task-driven GAN"></a>Task-driven GAN</h2><p>This article focuses on the GAN model. At present, there is a large amount of literature on closely related fields involving specific tasks.</p>
<ol>
<li>Semi-supervised learning</li>
<li>Transfer learning</li>
<li>Reinforcement learning</li>
<li>Multimodal learning</li>
</ol>
<p>GAN has been used in the field of feature learning, such as feature selection [277], hashing [278]-[285] and metric learning [286]. MisGAN [287] can learn from incomplete data through GAN. Evolutionary GAN (Evolutionary GAN) was proposed in [288]. Ponce et al. [289] combined GAN and genetic algorithm to evolve images for visual neurons. GAN is also used in other machine learning tasks [290], such as active learning [291], [292], online learning [293], ensemble learning [294], zero-sample learning [295], [296] and multi-task learning [297].</p>
<h1 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h1><h2 id="Maximum-likelihood-estimation-MLE"><a href="#Maximum-likelihood-estimation-MLE" class="headerlink" title="Maximum likelihood estimation (MLE)"></a>Maximum likelihood estimation (MLE)</h2><p>Not all generative models use MLE. Some generative models do not use MLE, but can be modified to use MLE (GANs fall into this category). It can be simply proved that minimizing the KL divergence (KLD) between p_data(x) and p_g(x) is equivalent to maximizing the log likelihood when the number of samples m increases:<br>$$<br>\begin{array}{l}<br>\theta^{*}=\underset{\theta}{\arg \min } K L D\left(p_{\text {data}} | p_{g}\right) \<br>=\underset{\theta}{\arg \min }-\int p_{\text {data}}(x) \log \frac{p_{g}(x)}{p_{\text {data}}(x)} d x \<br>=\arg \min \int p_{\text {data}}(x) \log p_{\text {data}}(x) d x \<br>\quad-\int p_{\text {data}}(x) \log p_{g}(x) d x \<br>=\arg \max <em>{\theta} \log p</em>{\text {data}}(x) \log <em>{g}(x) d x \<br>=\arg \max _{\theta} \lim _{m \rightarrow \infty} \frac{1}{m} \sum</em>{i=1}^{m} \log p_{g}\left(x_{i}\right)<br>\end{array}<br>$$</p>
<p>In order to ensure symbol consistency, the model probability distribution p_θ(x) is replaced with p_g(x). For more information on MLE and other statistical estimators, see Chapter 5 of [298].</p>
<h2 id="Model-collapse"><a href="#Model-collapse" class="headerlink" title="Model collapse"></a>Model collapse</h2><p>GANs are difficult to train, and in [26], [29] it has been observed that they are often affected by mode collapse [299], [300], where the generator learns to generate samples based on only a few data distribution patterns, and ignores Many other patterns (even if there are samples from missing patterns in the entire training data). In the worst case, the generator only generates a single sample (completely collapsed) [179], [301].</p>
<p>In this section, we first introduce two views on the collapse of the GAN model: the divergence view and the algorithm view. Then, we will introduce methods for solving model collapse by proposing new objective functions or new architectures, including objective function-based methods and architecture-based methods.</p>
<h2 id="Other-theoretical-issues"><a href="#Other-theoretical-issues" class="headerlink" title="Other theoretical issues"></a>Other theoretical issues</h2><p>Other theoretical issues include:</p>
<ol>
<li>Has GAN really learned the distribution?</li>
<li>Divergence/distance</li>
<li>Inverse mapping</li>
<li>Mathematical point of view (such as optimization)</li>
<li>Memory</li>
</ol>
<h1 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h1><p>As mentioned earlier, GAN is a powerful generative model that can generate realistic samples from a random vector z. We neither need to know the explicit true data distribution or make any other mathematical assumptions. These advantages make GAN can be widely used in many fields, such as image processing and computer vision, sequence data and so on.</p>
<h2 id="Image-processing-and-computer-vision"><a href="#Image-processing-and-computer-vision" class="headerlink" title="Image processing and computer vision"></a>Image processing and computer vision</h2><p>The most successful applications of GAN are in image processing and computer vision, such as image super-resolution, image generation and manipulation, and video processing.</p>
<p>Super resolution<br>Image composition and manipulation<br>Texture synthesis<br>Target Detection<br>Video application</p>
<h2 id="Sequence-data"><a href="#Sequence-data" class="headerlink" title="Sequence data"></a>Sequence data</h2><p>GAN has also made certain achievements in sequence data such as natural language, music, speech, audio [376], [377], time sequence [378]–[381], etc.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
    <article
  id="post-shallow_bot3"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/08/27/shallow_bot3/"
    >Think about Bot 3</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/08/27/shallow_bot3/" class="article-date">
  <time datetime="2020-08-27T18:50:55.000Z" itemprop="datePublished">2020-08-27</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/shallow-understanding/">shallow understanding</a>
  </div>
 
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>It is difficult to evaluate bot response. Although it can be done with BLEU, the automatic evaluation method of machine translation, the effect will not be very good. Almost every paper will spend money to hire people to do manual evaluation, design a set of evaluation mechanism to score, manual evaluation is more convincing. This is especially true for practical engineering applications, and users say that it is really good. Rather than simply take the biased indicators you mentioned and compare them with several methods or other company bots to show you are good.</p>
<h2 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h2><p>After reading some papers and communicating with front-line engineers who are doing bot applications, I have a little thought, and the summary is as follows:</p>
<ol>
<li><p>Do you want to be a bot? There is a popular saying that there are no useful bots on the market. To solve the problem of bots requires a lot of technological progress at the same time, and it may take a very long time. Now it is ridiculous to use this thing for business. My personal view is that bots that solve specific tasks, combined with current advanced technology, and do some framework tools, are not so far away. Although it is not easy, it is very meaningful and solves the bot problem in the vertical field. It is possible to solve the bot problem of open domain. It is precisely because it is not easy to raise the threshold, there will be real opportunities to give birth to some great technology companies.</p>
</li>
<li><p>Is it open domain or task-oriented? If it were me, I would choose the latter, because the former is just a dream, an unattainable dream that requires more technological breakthroughs. Task-oriented is more specific and more practical. It provides some solutions for specific businesses. Many companies are already doing it. Although a universal or extensible solution has not yet appeared, it must be a trend and a new one. Opportunity for a generation of bot companies.</p>
</li>
<li><p>Why is task-oriented bot difficult, and in which direction should it be used? End-to-end is an idealized model. Deep learning models are used to “capture” some features and “fit” some functions from a large amount of training data. Although very good results can be obtained, it is indeed very convenient to use , But embarrassment is embarrassment. Mass data cannot be obtained in a specific task. After the data scale is small, pure end-to-end becomes very tasteless. However, in real scenarios, many companies have certain data and bot needs. So the mature solution is to design some features, templates and rules for your specific business. When the customer’s business changes, you need Constantly maintaining the existing bot system is very time-consuming and laborious. Real scenarios often involve a lot of structured business data. It is impossible to generate response directly based on context purely and violently. Articles [8][9] all give very enlightening solutions. Apply end-to-end locally, rather than the whole, with technologies such as Information Extraction and Knowledge Graph to achieve a highly available framework system. This should be the development direction of task-oriented bots.</p>
</li>
<li><p>What factors should be related to the generation of response? The quality of the response needs to be linked to these features: (1) user query, the user’s question, what exactly the user is asking in this round of dialogue, and accurately understanding the user’s intention is crucial. (2) user modeling, modeling the user, including the user’s basic information, and more importantly, the mining of the user history conversation logs. This job is difficult, but at the same time it is also very good. It is also a technology company that proves its technology A great way. The mining of logs is very common now, not everyone is doing well, and the logs here are not generally set and structured indicators, but unstructured text logs, which are more difficult to mine. Another point is also seen in paper. User emotion and sentiment analysis are tasks that are studied in nlp. The user’s emotion is directly related to the success or failure of sales. If the technology is good enough, there can be enough factors to consider. The analysis is clear enough. Hanging the history in the model is not a good way, because the history is constantly growing, which will cause problems when the model captures information. A better way may be to build a user profile and so on, to precipitate the history as a vector Representation, or a kind of knowledge graph to represent a user. A bot with this ability is a personalized bot. (3) Knowledge, external knowledge source. When it comes to specific business, business data is also a kind of knowledge. How to model knowledge into the model and be more professional and accurate when generating dialogue is also a very important issue. Bot is a comprehensive problem, not only the difficulty of the system framework, but also the difficulty of modeling.</p>
</li>
<li><p>I have always felt that being a person and looking at problems can not be extreme. The world is not black and white, but a continuous value between the two. It is impossible to say that either it will be an open-domain giant bot or a bot that has no specific functions. You cannot just see that the existing bot is immature and the fantasy bot is out of reach. In this field, I also laughed at others for being able to get investment. There is no point in arguing. What is really meaningful is to dig deep into this field, find the pain points and difficulties, break them one by one, and constantly promote the development of this field, instead of being boring like some street-watchers! Before breakthroughs in many areas, it seemed that there was no light in sight, but after a few years, many of the problems that were difficult to solve at the time were not all in the Red Sea, were they all over the streets? It may be difficult to make a general-purpose bot for a long time, but there is still hope to make a bot solution with high availability and good scalability. You don’t need to be over-confident, and you don’t need to be humble, and do it steadily. That’s it.</p>
</li>
</ol>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p>[1] A Survey of Available Corpora for Building Data-Driven Dialogue Systems</p>
<p>[2] A Neural Conversational Model</p>
<p>[3] A Diversity-Promoting Objective Function for Neural Conversation Models</p>
<p>[4] A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</p>
<p>[5] Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</p>
<p>[6] A Persona-Based Neural Conversation Model</p>
<p>[7] Deep Reinforcement Learning for Dialogue Generation</p>
<p>[8] End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</p>
<p>[9] A Network-based End-to-End Trainable Task-oriented Dialogue System</p>
<p>[10] Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems</p>
<p>[11] A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</p>
<p>[12] A Dataset for Research on Short-Text Conversation</p>
<p>[13] The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/bot/" rel="tag">bot</a></li></ul>

    </footer>
  </div>

   
   
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">next page</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2017-2020
        <i class="ri-heart-fill heart_icon"></i> Hanqi ZHOU
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Hanqi ZHOU"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">Home</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">Blog</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/life">Life</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">About Me</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>